<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Towards Surveillance Video-and-Language Understanding</title>
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="css/style.css" media="screen"/>
</head>
<body>
    <div class="container">
        <h1 class="project-title">Towards Surveillance Video-and-Language Understanding: New Dataset, Baselines, and Challenges</h1>

        <div class="authors">
            <p>Tongtong Yuan<sup>1</sup>, Xuange Zhang<sup>1</sup>, Kun Liu<sup>2</sup>, Bo Liu<sup>1</sup>, Chen Chen<sup>2</sup>, Jian Jin<sup>3</sup>, Zhenzhen Jiao<sup>4</sup></p>
        </div>

        <div class="icon-container">
            <ul class="icon-list">
                <li class="icon-item">
                    <a href="https://github.com/Xuange923/Surveillance-Video-Understanding">
                        <img src="img/file-pdf.png" alt="Paper">
                        <h4><strong>Paper</strong></h4>
                    </a>
                </li>
                <li class="icon-item">
                    <a href="https://github.com/Xuange923/Surveillance-Video-Understanding">
                        <img src="img/github.png" alt="Code">
                        <h4><strong>Code</strong></h4>
                    </a>
                </li>
            </ul>
        </div>

        <h2>Abstract</h2>
        <p>Surveillance videos are an essential component of daily life with various critical applications, particularly in public security. However, current surveillance video tasks mainly focus on classifying and localizing anomalous events. [....] All the experiments highlight the necessity of constructing this dataset to advance surveillance AI.</p>
        <img src="https://i.postimg.cc/ZqyVxR0W/fig-visual.jpg" alt="Abstract Image">

        <h2>Experimental Tasks</h2>
        <ul>
            <li>Temporal Sentence Grounding in Videos (TSGV): This task focuses on temporal activity localization in a video based on a language query.</li>
            <li>Video Captioning (VC): Understanding a video clip and describing it with language.</li>
            <li>Dense Video Captioning (DVC): Involves generating the temporal localization and captioning of dense events in an untrimmed video.</li>
            <li>Multimodal Anomaly Detection (MAD): Utilizes captions as a text feature source to enhance traditional anomaly detection in complex surveillance videos.</li>
        </ul>

        <h2>Visualizations</h2>
        <div class="visualizations clearfix">
            <img src="https://i.postimg.cc/mhfbhhc7/fig-tsgv-2.jpg" alt="TSGV Visualization">
            <img src="https://i.postimg.cc/pVqj6Hwk/fig-vc.jpg" alt="VC Visualization">
            <img src="https://i.postimg.cc/wjd95twr/fig-dvc.jpg" alt="DVC Visualization">
            <img src="https://i.postimg.cc/V5PPFTWt/fig-mad.jpg" alt="MAD Captioning Results">
        </div>

        <h2>Links</h2>
        <p>Paper: <a href="https://github.com/Xuange923/Surveillance-Video-Understanding">https://github.com/Xuange923/Surveillance-Video-Understanding</a></p>
        <p>GitHub Project: <a href="https://github.com/Xuange923/Surveillance-Video-Understanding">https://github.com/Xuange923/Surveillance-Video-Understanding</a></p>
    </div>
</body>
</html>
